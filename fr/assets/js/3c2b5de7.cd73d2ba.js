"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[9970],{8453:(e,n,a)=>{a.d(n,{R:()=>o,x:()=>r});var s=a(6540);const i={},t=s.createContext(i);function o(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),s.createElement(t.Provider,{value:n},e.children)}},9535:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>d,frontMatter:()=>o,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"module-3-isaac/chapter-2","title":"Chapter 16: Isaac ROS Integration","description":"Integrating NVIDIA Isaac with ROS 2 for humanoid robotics applications","source":"@site/docs/module-3-isaac/chapter-2.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/chapter-2","permalink":"/hackathon-book-robotics/fr/docs/module-3-isaac/chapter-2","draft":false,"unlisted":false,"editUrl":"https://github.com/noormusarrat/hackathon-book-robotics/edit/main/docs/module-3-isaac/chapter-2.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Chapter 16: Isaac ROS Integration","description":"Integrating NVIDIA Isaac with ROS 2 for humanoid robotics applications"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 15: Introduction to NVIDIA Isaac","permalink":"/hackathon-book-robotics/fr/docs/module-3-isaac/chapter-1"},"next":{"title":"Chapter 17: Perception Pipelines with Isaac","permalink":"/hackathon-book-robotics/fr/docs/module-3-isaac/chapter-3"}}');var i=a(4848),t=a(8453);const o={sidebar_position:2,title:"Chapter 16: Isaac ROS Integration",description:"Integrating NVIDIA Isaac with ROS 2 for humanoid robotics applications"},r="Chapter 16: Isaac ROS Integration",c={},l=[{value:"1. Why this concept matters for humanoids",id:"1-why-this-concept-matters-for-humanoids",level:2},{value:"2. Theory",id:"2-theory",level:2},{value:"Isaac ROS Architecture",id:"isaac-ros-architecture",level:3},{value:"Isaac ROS Package Categories",id:"isaac-ros-package-categories",level:3},{value:"ROS 2 Communication Patterns in Isaac",id:"ros-2-communication-patterns-in-isaac",level:3},{value:"Performance Considerations",id:"performance-considerations",level:3},{value:"3. Implementation",id:"3-implementation",level:2},{value:"4. Hardware/GPU Notes",id:"4-hardwaregpu-notes",level:2},{value:"Isaac ROS GPU Requirements",id:"isaac-ros-gpu-requirements",level:3},{value:"Memory Management Strategies",id:"memory-management-strategies",level:3},{value:"Jetson Platform Specifics",id:"jetson-platform-specifics",level:3},{value:"Performance Optimization",id:"performance-optimization",level:3},{value:"5. Simulation Path",id:"5-simulation-path",level:2},{value:"6. Real-World Path",id:"6-real-world-path",level:2},{value:"7. Spec-Build-Test checklist",id:"7-spec-build-test-checklist",level:2},{value:"8. APA citations",id:"8-apa-citations",level:2}];function m(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"chapter-16-isaac-ros-integration",children:"Chapter 16: Isaac ROS Integration"})}),"\n",(0,i.jsx)(n.h2,{id:"1-why-this-concept-matters-for-humanoids",children:"1. Why this concept matters for humanoids"}),"\n",(0,i.jsx)(n.p,{children:"Isaac ROS integration is fundamental for humanoid robotics because it bridges the gap between NVIDIA's powerful hardware-accelerated perception and navigation capabilities and the widely adopted ROS 2 ecosystem. This integration allows humanoid robots to leverage Isaac's GPU-accelerated algorithms for perception, SLAM, and navigation while maintaining compatibility with the vast ROS 2 package ecosystem. The combination enables humanoid robots to perform complex perception tasks like real-time object detection, visual-inertial SLAM, and advanced navigation in dynamic environments, all while benefiting from ROS 2's robust communication, tooling, and package management. Without this integration, humanoid robots would either lack the computational power for advanced perception or be isolated from the broader robotics community's tools and algorithms."}),"\n",(0,i.jsx)(n.h2,{id:"2-theory",children:"2. Theory"}),"\n",(0,i.jsx)(n.h3,{id:"isaac-ros-architecture",children:"Isaac ROS Architecture"}),"\n",(0,i.jsx)(n.p,{children:"Isaac ROS is a collection of hardware-accelerated packages that enable developers to build high-performance robotics applications using the Robot Operating System (ROS). These packages are specifically designed to leverage NVIDIA's GPU architecture for accelerated processing, making them ideal for computationally intensive tasks required by humanoid robots."}),"\n",(0,i.jsx)(n.p,{children:"The architecture consists of several key layers:"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Transport Layer"}),": Handles efficient data transfer between different processing stages, including compressed image transport optimized for GPU processing."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Processing Layer"}),": Contains hardware-accelerated algorithms for perception, navigation, and manipulation tasks. These algorithms are implemented using NVIDIA's CUDA, TensorRT, and other acceleration libraries."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Interface Layer"}),": Provides ROS 2 interfaces (messages, services, actions) that allow seamless integration with other ROS 2 packages and tools."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Application Layer"}),": Contains reference applications and examples that demonstrate best practices for robotics development using Isaac ROS."]}),"\n",(0,i.jsx)(n.h3,{id:"isaac-ros-package-categories",children:"Isaac ROS Package Categories"}),"\n",(0,i.jsx)(n.p,{children:"Isaac ROS packages are organized into several functional categories:"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Perception Packages"}),": Include visual SLAM, object detection, depth processing, and sensor fusion algorithms that run on NVIDIA GPUs."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Navigation Packages"}),": Provide path planning, obstacle avoidance, and localization capabilities optimized for mobile robots including humanoid platforms."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Manipulation Packages"}),": Offer tools for robotic arm control, grasp planning, and manipulation tasks."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Simulation Packages"}),": Enable integration with Isaac Sim for testing and validation of robotics applications."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Utilities"}),": Provide common tools for image processing, point cloud operations, and system monitoring."]}),"\n",(0,i.jsx)(n.h3,{id:"ros-2-communication-patterns-in-isaac",children:"ROS 2 Communication Patterns in Isaac"}),"\n",(0,i.jsx)(n.p,{children:"Isaac ROS packages follow standard ROS 2 communication patterns while optimizing for GPU-accelerated processing:"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Publish-Subscribe Model"}),": Isaac packages use ROS 2 topics for streaming sensor data and processing results, with optimized message types for GPU processing."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Service-Client Model"}),": Used for configuration and control operations that don't require real-time processing."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Action Model"}),": For long-running operations like navigation goals or manipulation tasks that provide feedback during execution."]}),"\n",(0,i.jsx)(n.h3,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,i.jsx)(n.p,{children:"Isaac ROS integration must account for several performance factors:"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Memory Management"}),": Efficient allocation and deallocation of GPU memory to minimize overhead and maximize throughput."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Data Transfer"}),": Minimizing data transfers between CPU and GPU memory to reduce latency."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Pipeline Optimization"}),": Overlapping computation stages to maximize GPU utilization and maintain real-time performance."]}),"\n",(0,i.jsx)(n.h2,{id:"3-implementation",children:"3. Implementation"}),"\n",(0,i.jsx)(n.p,{children:"Let's implement the Isaac ROS integration for humanoid robotics:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# isaac_humanoid_navigation/isaac_humanoid_navigation/isaac_ros_manager.py\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, CameraInfo, Imu, LaserScan\nfrom nav_msgs.msg import Odometry, OccupancyGrid, Path\nfrom geometry_msgs.msg import PoseStamped, Twist\nfrom std_msgs.msg import Header, Bool\nfrom builtin_interfaces.msg import Duration\nimport numpy as np\nimport threading\nfrom typing import Dict, Any, Optional\nimport time\n\nclass IsaacROSManager(Node):\n    """\n    Main manager for Isaac ROS integration in humanoid robotics\n    """\n    def __init__(self):\n        super().__init__(\'isaac_ros_manager\')\n\n        # Initialize components\n        self.isaac_components_initialized = False\n        self.synchronization_lock = threading.Lock()\n\n        # Timestamp synchronization\n        self.latest_sensor_timestamps = {}\n        self.synchronization_window = 0.1  # 100ms window for synchronization\n\n        # Publishers for Isaac ROS outputs\n        self.odom_pub = self.create_publisher(Odometry, \'/isaac_ros/odometry\', 10)\n        self.map_pub = self.create_publisher(OccupancyGrid, \'/isaac_ros/map\', 10)\n        self.path_pub = self.create_publisher(Path, \'/isaac_ros/local_plan\', 10)\n        self.status_pub = self.create_publisher(Bool, \'/isaac_ros/initialized\', 10)\n\n        # Subscribers for sensor data\n        self.camera_sub = self.create_subscription(\n            Image, \'/camera/rgb/image_raw\', self.camera_callback, 10\n        )\n        self.imu_sub = self.create_subscription(\n            Imu, \'/imu/data\', self.imu_callback, 10\n        )\n        self.lidar_sub = self.create_subscription(\n            LaserScan, \'/scan\', self.lidar_callback, 10\n        )\n        self.camera_info_sub = self.create_subscription(\n            CameraInfo, \'/camera/rgb/camera_info\', self.camera_info_callback, 10\n        )\n\n        # Isaac ROS component controllers\n        self.visual_slam_enabled = True\n        self.perception_enabled = True\n        self.navigation_enabled = True\n\n        # Timer for Isaac ROS component management\n        self.manager_timer = self.create_timer(1.0, self.manage_isaac_components)\n\n        # Initialize Isaac ROS components\n        self.initialize_isaac_components()\n\n        self.get_logger().info(\'Isaac ROS Manager initialized\')\n\n    def camera_callback(self, msg):\n        """Handle camera data for Isaac ROS processing"""\n        with self.synchronization_lock:\n            self.latest_sensor_timestamps[\'camera\'] = msg.header.stamp\n            # In a real implementation, this would interface with Isaac ROS camera processing\n            self.get_logger().debug(f\'Camera data received at {msg.header.stamp.sec}.{msg.header.stamp.nanosec}\')\n\n    def imu_callback(self, msg):\n        """Handle IMU data for Isaac ROS processing"""\n        with self.synchronization_lock:\n            self.latest_sensor_timestamps[\'imu\'] = msg.header.stamp\n            # In a real implementation, this would interface with Isaac ROS IMU processing\n            self.get_logger().debug(f\'IMU data received at {msg.header.stamp.sec}.{msg.header.stamp.nanosec}\')\n\n    def lidar_callback(self, msg):\n        """Handle LIDAR data for Isaac ROS processing"""\n        with self.synchronization_lock:\n            self.latest_sensor_timestamps[\'lidar\'] = msg.header.stamp\n            # In a real implementation, this would interface with Isaac ROS LIDAR processing\n            self.get_logger().debug(f\'LIDAR data received at {msg.header.stamp.sec}.{msg.header.stamp.nanosec}\')\n\n    def camera_info_callback(self, msg):\n        """Handle camera info for Isaac ROS processing"""\n        with self.synchronization_lock:\n            self.latest_sensor_timestamps[\'camera_info\'] = msg.header.stamp\n            # Store camera calibration for Isaac ROS processing\n            self.get_logger().debug(f\'Camera info received at {msg.header.stamp.sec}.{msg.header.stamp.nanosec}\')\n\n    def initialize_isaac_components(self):\n        """Initialize Isaac ROS components"""\n        self.get_logger().info(\'Initializing Isaac ROS components...\')\n\n        # This is a simulation of Isaac ROS component initialization\n        # In a real implementation, this would start Isaac ROS nodes\n        try:\n            # Initialize visual SLAM component\n            if self.visual_slam_enabled:\n                self.initialize_visual_slam()\n\n            # Initialize perception component\n            if self.perception_enabled:\n                self.initialize_perception()\n\n            # Initialize navigation component\n            if self.navigation_enabled:\n                self.initialize_navigation()\n\n            self.isaac_components_initialized = True\n            self.get_logger().info(\'All Isaac ROS components initialized successfully\')\n\n            # Publish initialization status\n            status_msg = Bool()\n            status_msg.data = True\n            self.status_pub.publish(status_msg)\n\n        except Exception as e:\n            self.get_logger().error(f\'Error initializing Isaac ROS components: {e}\')\n            self.isaac_components_initialized = False\n\n    def initialize_visual_slam(self):\n        """Initialize Isaac Visual SLAM component"""\n        self.get_logger().info(\'Initializing Isaac Visual SLAM...\')\n        # In a real implementation, this would configure and start Isaac Visual SLAM\n        # Example: self.visual_slam_node = IsaacVisualSlamNode()\n        time.sleep(0.5)  # Simulate initialization time\n\n    def initialize_perception(self):\n        """Initialize Isaac Perception component"""\n        self.get_logger().info(\'Initializing Isaac Perception...\')\n        # In a real implementation, this would configure and start Isaac Perception\n        # Example: self.perception_node = IsaacPerceptionNode()\n        time.sleep(0.3)  # Simulate initialization time\n\n    def initialize_navigation(self):\n        """Initialize Isaac Navigation component"""\n        self.get_logger().info(\'Initializing Isaac Navigation...\')\n        # In a real implementation, this would configure and start Isaac Navigation\n        # Example: self.navigation_node = IsaacNavigationNode()\n        time.sleep(0.4)  # Simulate initialization time\n\n    def manage_isaac_components(self):\n        """Manage Isaac ROS components"""\n        if not self.isaac_components_initialized:\n            self.get_logger().warn(\'Isaac ROS components not initialized, attempting re-initialization\')\n            self.initialize_isaac_components()\n            return\n\n        # Check component health and performance\n        self.check_component_health()\n\n        # Update component configurations if needed\n        self.update_component_configurations()\n\n        # Log status\n        self.get_logger().debug(\'Isaac ROS components status: All healthy\')\n\n    def check_component_health(self):\n        """Check health of Isaac ROS components"""\n        # In a real implementation, this would check if Isaac ROS nodes are running\n        # and responding to requests\n        pass\n\n    def update_component_configurations(self):\n        """Update configurations for Isaac ROS components"""\n        # In a real implementation, this would update parameters for Isaac ROS nodes\n        # based on current operational requirements\n        pass\n\n    def synchronize_sensor_data(self):\n        """Synchronize sensor data for Isaac ROS processing"""\n        with self.synchronization_lock:\n            if len(self.latest_sensor_timestamps) < 3:  # Need at least 3 sensor types\n                return False\n\n            # Get the most recent timestamp\n            timestamps = list(self.latest_sensor_timestamps.values())\n            latest_time = max(timestamps, key=lambda x: (x.sec, x.nanosec))\n\n            # Check if all timestamps are within synchronization window\n            for timestamp in timestamps:\n                time_diff = abs(\n                    (latest_time.sec + latest_time.nanosec / 1e9) -\n                    (timestamp.sec + timestamp.nanosec / 1e9)\n                )\n                if time_diff > self.synchronization_window:\n                    return False\n\n            return True\n\n    def process_sensor_fusion(self):\n        """Process sensor fusion using Isaac ROS"""\n        # In a real implementation, this would interface with Isaac ROS sensor fusion\n        # components to combine data from multiple sensors\n        pass\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = IsaacROSManager()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        node.get_logger().info(\'Shutting down Isaac ROS Manager\')\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,i.jsx)(n.p,{children:"Create the Isaac ROS integration configuration:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# isaac_humanoid_navigation/config/isaac_ros_config.yaml\nisaac_ros_manager:\n  ros__parameters:\n    # Component enable flags\n    components:\n      visual_slam_enabled: true\n      perception_enabled: true\n      navigation_enabled: true\n      manipulation_enabled: false\n\n    # Sensor synchronization\n    synchronization:\n      window_duration: 0.1  # 100ms window\n      max_delay_tolerance: 0.05  # 50ms max delay\n      required_sensors: ["camera", "imu", "lidar"]\n\n    # GPU settings\n    gpu:\n      device_id: 0\n      memory_fraction: 0.8  # Use 80% of available GPU memory\n      enable_tensorrt: true\n      tensorrt_precision: "fp16"  # or "fp32", "int8"\n\n    # Processing parameters\n    processing:\n      frame_rate: 10.0  # Hz\n      queue_size: 10\n      max_queue_size: 100\n      enable_multithreading: true\n\n    # Isaac Visual SLAM parameters\n    visual_slam:\n      enable_rectification: true\n      enable_imu_fusion: true\n      map_frame: "map"\n      odom_frame: "odom"\n      base_frame: "base_link"\n      publish_tf: true\n\n    # Isaac Perception parameters\n    perception:\n      detection_threshold: 0.7\n      tracking_enabled: true\n      feature_extraction_enabled: true\n      max_objects: 50\n\n    # Isaac Navigation parameters\n    navigation:\n      planner_frequency: 5.0\n      controller_frequency: 20.0\n      recovery_enabled: true\n      global_frame: "map"\n      robot_base_frame: "base_link"\n      transform_tolerance: 0.3\n\n    # Logging and diagnostics\n    logging:\n      enable_diagnostics: true\n      diagnostic_frequency: 1.0\n      log_level: "INFO"\n'})}),"\n",(0,i.jsx)(n.p,{children:"Create the launch file for Isaac ROS integration:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:"\x3c!-- isaac_humanoid_navigation/launch/isaac_ros_integration.launch.py --\x3e\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\nfrom launch.actions import DeclareLaunchArgument\nfrom launch.substitutions import LaunchConfiguration\nfrom ament_index_python.packages import get_package_share_directory\nimport os\n\ndef generate_launch_description():\n    # Declare launch arguments\n    use_sim_time = LaunchConfiguration('use_sim_time')\n    namespace = LaunchConfiguration('namespace')\n\n    return LaunchDescription([\n        # Declare launch arguments\n        DeclareLaunchArgument(\n            'use_sim_time',\n            default_value='false',\n            description='Use simulation (Gazebo) clock if true'\n        ),\n        DeclareLaunchArgument(\n            'namespace',\n            default_value='',\n            description='Robot namespace'\n        ),\n\n        # Isaac ROS Manager\n        Node(\n            package='isaac_humanoid_navigation',\n            executable='isaac_ros_manager',\n            name='isaac_ros_manager',\n            namespace=namespace,\n            parameters=[\n                os.path.join(\n                    get_package_share_directory('isaac_humanoid_navigation'),\n                    'config',\n                    'isaac_ros_config.yaml'\n                ),\n                {'use_sim_time': use_sim_time}\n            ],\n            output='screen',\n            respawn=True,\n            respawn_delay=2\n        ),\n\n        # Isaac ROS Visual SLAM Node (example)\n        Node(\n            package='isaac_ros_visual_slam',\n            executable='isaac_ros_visual_slam_node',\n            name='visual_slam_node',\n            namespace=namespace,\n            parameters=[\n                {\n                    'enable_rectification': True,\n                    'enable_imu_fusion': True,\n                    'map_frame': 'map',\n                    'odom_frame': 'odom',\n                    'base_frame': 'base_link',\n                    'publish_tf': True,\n                    'use_sim_time': use_sim_time\n                }\n            ],\n            remappings=[\n                ('/visual_slam/camera/imu', '/imu/data'),\n                ('/visual_slam/camera/camera_info', '/camera/rgb/camera_info'),\n                ('/visual_slam/camera/image', '/camera/rgb/image_raw'),\n                ('/visual_slam/visual_odometry', '/visual_slam/odometry'),\n                ('/visual_slam/acceleration', '/acceleration'),\n                ('/visual_slam/gyroscope', '/gyroscope')\n            ],\n            output='screen'\n        ),\n\n        # Isaac ROS Image Pipeline (Color Conversion)\n        Node(\n            package='isaac_ros_image_pipeline',\n            executable='isaac_ros_color_convert',\n            name='color_convert_node',\n            namespace=namespace,\n            parameters=[\n                {\n                    'input_encoding': 'rgb8',\n                    'output_encoding': 'bgr8',\n                    'use_sim_time': use_sim_time\n                }\n            ],\n            remappings=[\n                ('image_raw', '/camera/rgb/image_raw'),\n                ('image_color_converted', '/camera/rgb/image_converted')\n            ],\n            output='screen'\n        ),\n\n        # Isaac ROS Depth Preprocessor\n        Node(\n            package='isaac_ros_depth_preprocessor',\n            executable='isaac_ros_depth_preprocessor',\n            name='depth_preprocessor_node',\n            namespace=namespace,\n            parameters=[\n                {\n                    'input_encoding': '16UC1',\n                    'output_encoding': '32FC1',\n                    'use_sim_time': use_sim_time\n                }\n            ],\n            remappings=[\n                ('depth/image', '/camera/depth/image_raw'),\n                ('depth/image_processed', '/camera/depth/image_processed')\n            ],\n            output='screen'\n        )\n    ])\n"})}),"\n",(0,i.jsx)(n.p,{children:"Create a diagnostic node to monitor Isaac ROS integration:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# isaac_humanoid_navigation/isaac_humanoid_navigation/isaac_ros_diagnostics.py\nimport rclpy\nfrom rclpy.node import Node\nfrom diagnostic_msgs.msg import DiagnosticArray, DiagnosticStatus, KeyValue\nfrom std_msgs.msg import Header\nfrom sensor_msgs.msg import BatteryState\nfrom geometry_msgs.msg import Twist\nimport psutil\nimport GPUtil\nimport time\nfrom datetime import datetime\n\nclass IsaacROSDiagnostics(Node):\n    \"\"\"\n    Diagnostic node for monitoring Isaac ROS integration\n    \"\"\"\n    def __init__(self):\n        super().__init__('isaac_ros_diagnostics')\n\n        # Publishers\n        self.diag_pub = self.create_publisher(DiagnosticArray, '/diagnostics', 10)\n        self.battery_pub = self.create_publisher(BatteryState, '/battery_state', 10)\n\n        # Subscribers for Isaac ROS status\n        self.cmd_vel_sub = self.create_subscription(\n            Twist, '/cmd_vel', self.cmd_vel_callback, 10\n        )\n\n        # Timer for diagnostics publishing\n        self.diag_timer = self.create_timer(1.0, self.publish_diagnostics)\n\n        # Internal state tracking\n        self.last_cmd_vel_time = time.time()\n        self.cmd_vel_count = 0\n\n        self.get_logger().info('Isaac ROS Diagnostics node initialized')\n\n    def cmd_vel_callback(self, msg):\n        \"\"\"Track command velocity messages\"\"\"\n        self.last_cmd_vel_time = time.time()\n        self.cmd_vel_count += 1\n\n    def publish_diagnostics(self):\n        \"\"\"Publish diagnostic information\"\"\"\n        diag_array = DiagnosticArray()\n        diag_array.header.stamp = self.get_clock().now().to_msg()\n\n        # System diagnostics\n        system_diag = self.get_system_diagnostics()\n        diag_array.status.append(system_diag)\n\n        # Isaac ROS component diagnostics\n        isaac_diag = self.get_isaac_component_diagnostics()\n        diag_array.status.append(isaac_diag)\n\n        # Navigation diagnostics\n        nav_diag = self.get_navigation_diagnostics()\n        diag_array.status.append(nav_diag)\n\n        # Publish diagnostics\n        self.diag_pub.publish(diag_array)\n\n        # Publish battery state (simulated)\n        battery_msg = self.get_battery_state()\n        self.battery_pub.publish(battery_msg)\n\n    def get_system_diagnostics(self):\n        \"\"\"Get system-level diagnostic information\"\"\"\n        status = DiagnosticStatus()\n        status.name = 'System Status'\n        status.hardware_id = 'system'\n\n        # CPU usage\n        cpu_percent = psutil.cpu_percent(interval=None)\n\n        # Memory usage\n        memory = psutil.virtual_memory()\n        memory_percent = memory.percent\n\n        # GPU usage (if available)\n        gpu_percent = 0\n        gpu_memory_percent = 0\n        try:\n            gpus = GPUtil.getGPUs()\n            if gpus:\n                gpu = gpus[0]  # Use first GPU\n                gpu_percent = gpu.load * 100\n                gpu_memory_percent = gpu.memoryUtil * 100\n        except:\n            # GPUtil not available or no GPU detected\n            pass\n\n        # Determine status level\n        if cpu_percent > 90 or memory_percent > 90 or gpu_percent > 90:\n            status.level = DiagnosticStatus.ERROR\n            status.message = 'High resource usage detected'\n        elif cpu_percent > 75 or memory_percent > 75 or gpu_percent > 75:\n            status.level = DiagnosticStatus.WARN\n            status.message = 'Elevated resource usage'\n        else:\n            status.level = DiagnosticStatus.OK\n            status.message = 'System resources nominal'\n\n        # Add key-value pairs\n        status.values = [\n            KeyValue(key='CPU Usage (%)', value=f'{cpu_percent:.2f}'),\n            KeyValue(key='Memory Usage (%)', value=f'{memory_percent:.2f}'),\n            KeyValue(key='GPU Usage (%)', value=f'{gpu_percent:.2f}'),\n            KeyValue(key='GPU Memory Usage (%)', value=f'{gpu_memory_percent:.2f}'),\n            KeyValue(key='System Uptime (s)', value=f'{time.time():.0f}'),\n        ]\n\n        return status\n\n    def get_isaac_component_diagnostics(self):\n        \"\"\"Get Isaac ROS component diagnostic information\"\"\"\n        status = DiagnosticStatus()\n        status.name = 'Isaac ROS Components'\n        status.hardware_id = 'isaac_ros'\n\n        # Simulate checking Isaac ROS component status\n        # In a real implementation, this would interface with Isaac ROS nodes\n        components = {\n            'Visual SLAM': True,\n            'Perception': True,\n            'Navigation': True,\n            'Image Pipeline': True\n        }\n\n        active_components = sum(1 for active in components.values() if active)\n        total_components = len(components)\n\n        if active_components == total_components:\n            status.level = DiagnosticStatus.OK\n            status.message = f'All {total_components} Isaac ROS components active'\n        elif active_components == 0:\n            status.level = DiagnosticStatus.ERROR\n            status.message = 'No Isaac ROS components active'\n        else:\n            status.level = DiagnosticStatus.WARN\n            status.message = f'{active_components}/{total_components} Isaac ROS components active'\n\n        # Add key-value pairs\n        status.values = [\n            KeyValue(key='Total Components', value=str(total_components)),\n            KeyValue(key='Active Components', value=str(active_components)),\n            KeyValue(key='Visual SLAM', value='OK' if components['Visual SLAM'] else 'ERROR'),\n            KeyValue(key='Perception', value='OK' if components['Perception'] else 'ERROR'),\n            KeyValue(key='Navigation', value='OK' if components['Navigation'] else 'ERROR'),\n            KeyValue(key='Image Pipeline', value='OK' if components['Image Pipeline'] else 'ERROR'),\n        ]\n\n        return status\n\n    def get_navigation_diagnostics(self):\n        \"\"\"Get navigation diagnostic information\"\"\"\n        status = DiagnosticStatus()\n        status.name = 'Navigation Status'\n        status.hardware_id = 'navigation'\n\n        # Check if receiving velocity commands recently\n        time_since_cmd = time.time() - self.last_cmd_vel_time\n        if time_since_cmd > 5.0:  # No commands for 5 seconds\n            status.level = DiagnosticStatus.WARN\n            status.message = 'No velocity commands received recently'\n        else:\n            status.level = DiagnosticStatus.OK\n            status.message = 'Receiving velocity commands normally'\n\n        # Add key-value pairs\n        status.values = [\n            KeyValue(key='Commands Received', value=str(self.cmd_vel_count)),\n            KeyValue(key='Time Since Last Cmd (s)', value=f'{time_since_cmd:.2f}'),\n            KeyValue(key='Last Cmd Vel (linear.x)', value='0.0'),  # Would need to track actual values\n            KeyValue(key='Last Cmd Vel (angular.z)', value='0.0'),\n        ]\n\n        return status\n\n    def get_battery_state(self):\n        \"\"\"Get simulated battery state\"\"\"\n        battery_msg = BatteryState()\n        battery_msg.header.stamp = self.get_clock().now().to_msg()\n        battery_msg.header.frame_id = 'battery'\n\n        # Simulated values\n        battery_msg.voltage = 12.6  # volts\n        battery_msg.current = -2.5  # amps (negative = discharging)\n        battery_msg.charge = 80.0   # percentage\n        battery_msg.capacity = 10.0 # Ah\n        battery_msg.design_capacity = 12.0  # Ah\n        battery_msg.percentage = 0.8  # 80%\n        battery_msg.power_supply_status = BatteryState.POWER_SUPPLY_STATUS_DISCHARGING\n        battery_msg.power_supply_health = BatteryState.POWER_SUPPLY_HEALTH_GOOD\n        battery_msg.power_supply_technology = BatteryState.POWER_SUPPLY_TECHNOLOGY_LION\n        battery_msg.present = True\n\n        return battery_msg\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = IsaacROSDiagnostics()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        node.get_logger().info('Shutting down Isaac ROS Diagnostics')\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,i.jsx)(n.h2,{id:"4-hardwaregpu-notes",children:"4. Hardware/GPU Notes"}),"\n",(0,i.jsx)(n.h3,{id:"isaac-ros-gpu-requirements",children:"Isaac ROS GPU Requirements"}),"\n",(0,i.jsx)(n.p,{children:"Isaac ROS packages have specific GPU requirements based on the algorithms being used:"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Visual SLAM Packages"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Minimum"}),": RTX 4070 Ti (12GB VRAM) or Jetson Orin NX"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Recommended"}),": RTX 4080/4090 (16-24GB VRAM) or Jetson AGX Orin"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Memory"}),": 4-8GB for basic visual SLAM, 8-12GB for visual-inertial SLAM"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Compute"}),": CUDA Compute Capability 6.0 or higher"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Perception Packages"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Object Detection"}),": 4-8GB VRAM depending on model size"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Feature Extraction"}),": 2-4GB VRAM"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Image Processing"}),": 1-2GB VRAM"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"TensorRT Acceleration"}),": Recommended for real-time performance"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Navigation Packages"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Path Planning"}),": 1-2GB VRAM"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Costmap Processing"}),": 2-4GB VRAM"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Obstacle Detection"}),": 2-4GB VRAM"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"memory-management-strategies",children:"Memory Management Strategies"}),"\n",(0,i.jsx)(n.p,{children:"For optimal Isaac ROS performance:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Memory Pooling"}),": Pre-allocate GPU memory pools to reduce allocation overhead"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Zero-Copy Memory"}),": Use CUDA zero-copy memory for frequent CPU-GPU transfers"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Unified Memory"}),": Leverage CUDA unified memory for automatic management"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Memory Monitoring"}),": Continuously monitor GPU memory usage to prevent overflow"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"jetson-platform-specifics",children:"Jetson Platform Specifics"}),"\n",(0,i.jsx)(n.p,{children:"When running Isaac ROS on Jetson platforms:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Memory Architecture"}),": Jetson platforms use unified memory architecture, which simplifies memory management"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Power Management"}),": Configure Jetson to operate in MAX performance mode for Isaac ROS"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Thermal Management"}),": Ensure adequate cooling for sustained Isaac ROS operation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"I/O Bandwidth"}),": Maximize camera and sensor data bandwidth"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"TensorRT Integration"}),": Use TensorRT for optimized deep learning inference"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"CUDA Streams"}),": Use multiple CUDA streams for overlapping operations"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Async Processing"}),": Implement asynchronous processing to maximize GPU utilization"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Batch Processing"}),": Process multiple inputs simultaneously when possible"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"5-simulation-path",children:"5. Simulation Path"}),"\n",(0,i.jsx)(n.p,{children:"To implement Isaac ROS integration in simulation:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Isaac Sim Setup"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Launch Isaac Sim with humanoid robot and sensors\ncd ~/isaac-sim\npython3 -m omni.isaac.kit --summary-cache-path ./cache\n\n# Load humanoid robot with Isaac-compatible sensors\n# Configure camera, IMU, LIDAR sensors in simulation\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Isaac ROS Integration Testing"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Launch Isaac ROS integration in simulation\nros2 launch isaac_humanoid_navigation isaac_ros_integration_sim.launch.py\n\n# Test sensor data flow\nros2 topic echo /isaac_ros/odometry\nros2 topic echo /isaac_ros/map\nros2 topic echo /diagnostics\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Performance Validation"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Test Isaac ROS component initialization"}),"\n",(0,i.jsx)(n.li,{children:"Validate sensor synchronization"}),"\n",(0,i.jsx)(n.li,{children:"Measure processing latency"}),"\n",(0,i.jsx)(n.li,{children:"Verify diagnostic reporting"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"6-real-world-path",children:"6. Real-World Path"}),"\n",(0,i.jsx)(n.p,{children:"For real-world deployment of Isaac ROS integration:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Hardware Setup"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Install Isaac ROS packages on humanoid robot platform"}),"\n",(0,i.jsx)(n.li,{children:"Configure GPU and CUDA drivers"}),"\n",(0,i.jsx)(n.li,{children:"Connect sensors (cameras, IMU, LIDAR)"}),"\n",(0,i.jsx)(n.li,{children:"Verify sensor calibration and timing"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"System Integration"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Build Isaac ROS workspace\ncd ~/isaac_ros_ws\ncolcon build --packages-select isaac_humanoid_navigation\nsource install/setup.bash\n\n# Launch Isaac ROS integration on robot\nros2 launch isaac_humanoid_navigation isaac_ros_integration.launch.py\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Validation and Testing"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Test sensor data processing in real environments"}),"\n",(0,i.jsx)(n.li,{children:"Validate Isaac ROS component health"}),"\n",(0,i.jsx)(n.li,{children:"Verify navigation and perception capabilities"}),"\n",(0,i.jsx)(n.li,{children:"Ensure system stability and safety"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"7-spec-build-test-checklist",children:"7. Spec-Build-Test checklist"}),"\n",(0,i.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Isaac ROS manager node implemented and functional"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Sensor synchronization working correctly"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Isaac ROS component initialization implemented"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Diagnostic monitoring system functional"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Configuration parameters properly set"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Launch files created and tested"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","GPU memory management implemented"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Performance monitoring in place"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Safety checks and error handling functional"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Isaac ROS component health monitoring working"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Battery and system diagnostics implemented"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Isaac ROS integration validated in simulation"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"8-apa-citations",children:"8. APA citations"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["NVIDIA Corporation. (2023). ",(0,i.jsx)(n.em,{children:"Isaac ROS: Hardware Accelerated Perception and Navigation"}),". NVIDIA Developer Documentation. Retrieved from ",(0,i.jsx)(n.a,{href:"https://docs.nvidia.com/isaac/isaac_ros/",children:"https://docs.nvidia.com/isaac/isaac_ros/"})]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Quigley, M., Gerkey, B., & Smart, W. D. (2009). Programming robots with ROS: A practical introduction to the Robot Operating System. ",(0,i.jsx)(n.em,{children:"Communications of the ACM"}),", 57(9), 82-91."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Fox, D., Burgard, W., & Thrun, S. (1997). The dynamic window approach to collision avoidance. ",(0,i.jsx)(n.em,{children:"IEEE Robotics & Automation Magazine"}),", 4(1), 23-33."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Sturm, J., Engelhard, N., Endres, F., Burgard, W., & Cremers, D. (2012). A benchmark for the evaluation of RGB-D SLAM systems. ",(0,i.jsx)(n.em,{children:"Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems"}),", 573-580."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Mur-Artal, R., Montiel, J. M. M., & Tard\xf3s, J. D. (2015). ORB-SLAM: A versatile and accurate monocular SLAM system. ",(0,i.jsx)(n.em,{children:"IEEE Transactions on Robotics"}),", 31(5), 1147-1163."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Endres, F., Hess, J., Sturm, J., Cvi\u0161i\u0107, I., Englehard, N., Grisetti, G., ... & Burgard, W. (2012). An evaluation of the RGB-D SLAM system. ",(0,i.jsx)(n.em,{children:"Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems"}),", 1691-1696."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Lupton, T., & Sukkarieh, S. (2012). Visual-inertial-aided navigation for high-dynamic motion in built environments without initial conditions. ",(0,i.jsx)(n.em,{children:"IEEE Transactions on Robotics"}),", 28(1), 61-76."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Forster, C., Pizzoli, M., & Scaramuzza, D. (2014). SVO: Fast semi-direct monocular visual odometry. ",(0,i.jsx)(n.em,{children:"IEEE International Conference on Robotics and Automation"}),", 15-22."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Engel, J., Sch\xf6ps, T., & Cremers, D. (2014). LSD-SLAM: Large-scale direct monocular SLAM. ",(0,i.jsx)(n.em,{children:"European Conference on Computer Vision"}),", 834-849."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["K\xfcmmerle, R., Grisetti, G., Strasdat, H., Konolige, K., & Burgard, W. (2011). g2o: A general framework for graph optimization. ",(0,i.jsx)(n.em,{children:"IEEE International Conference on Robotics and Automation"}),", 3607-3613)."]}),"\n"]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(m,{...e})}):m(e)}}}]);