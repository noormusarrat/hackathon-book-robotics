"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[3993],{7793:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>r,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"module-3-isaac/exercises/index","title":"Module 3 Exercises: NVIDIA Isaac - Perception + Navigation","description":"Exercises for implementing perception and navigation systems using NVIDIA Isaac","source":"@site/docs/module-3-isaac/exercises/index.md","sourceDirName":"module-3-isaac/exercises","slug":"/module-3-isaac/exercises/","permalink":"/hackathon-book-robotics/docs/module-3-isaac/exercises/","draft":false,"unlisted":false,"editUrl":"https://github.com/noormusarrat/hackathon-book-robotics/edit/main/docs/module-3-isaac/exercises/index.md","tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"sidebar_position":8,"title":"Module 3 Exercises: NVIDIA Isaac - Perception + Navigation","description":"Exercises for implementing perception and navigation systems using NVIDIA Isaac"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 21: Advanced AI Control for Bipedal Robots","permalink":"/hackathon-book-robotics/docs/module-3-isaac/chapter-7"},"next":{"title":"Module 3 Examples: Isaac Perception and Navigation Code Samples","permalink":"/hackathon-book-robotics/docs/module-3-isaac/examples/"}}');var a=i(4848),t=i(8453);const r={sidebar_position:8,title:"Module 3 Exercises: NVIDIA Isaac - Perception + Navigation",description:"Exercises for implementing perception and navigation systems using NVIDIA Isaac"},o="Module 3 Exercises: NVIDIA Isaac - Perception + Navigation",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Exercise 1: Isaac Perception Pipeline Implementation",id:"exercise-1-isaac-perception-pipeline-implementation",level:2},{value:"Objective",id:"objective",level:3},{value:"Tasks",id:"tasks",level:3},{value:"Requirements",id:"requirements",level:3},{value:"Code Template",id:"code-template",level:3},{value:"Evaluation Criteria",id:"evaluation-criteria",level:3},{value:"Exercise 2: Isaac SLAM System Integration",id:"exercise-2-isaac-slam-system-integration",level:2},{value:"Objective",id:"objective-1",level:3},{value:"Tasks",id:"tasks-1",level:3},{value:"Requirements",id:"requirements-1",level:3},{value:"Code Template",id:"code-template-1",level:3},{value:"Evaluation Criteria",id:"evaluation-criteria-1",level:3},{value:"Exercise 3: Isaac Navigation Implementation",id:"exercise-3-isaac-navigation-implementation",level:2},{value:"Objective",id:"objective-2",level:3},{value:"Tasks",id:"tasks-2",level:3},{value:"Requirements",id:"requirements-2",level:3},{value:"Code Template",id:"code-template-2",level:3},{value:"Evaluation Criteria",id:"evaluation-criteria-2",level:3},{value:"Exercise 4: Advanced AI Control for Bipedal Locomotion",id:"exercise-4-advanced-ai-control-for-bipedal-locomotion",level:2},{value:"Objective",id:"objective-3",level:3},{value:"Tasks",id:"tasks-3",level:3},{value:"Requirements",id:"requirements-3",level:3},{value:"Code Template",id:"code-template-3",level:3},{value:"Evaluation Criteria",id:"evaluation-criteria-3",level:3},{value:"Exercise 5: Isaac Perception-Navigation Integration",id:"exercise-5-isaac-perception-navigation-integration",level:2},{value:"Objective",id:"objective-4",level:3},{value:"Tasks",id:"tasks-4",level:3},{value:"Requirements",id:"requirements-4",level:3},{value:"Evaluation Criteria",id:"evaluation-criteria-4",level:3},{value:"Self-Assessment Questions",id:"self-assessment-questions",level:2},{value:"Project Extension",id:"project-extension",level:2},{value:"Resources and References",id:"resources-and-references",level:2},{value:"Solution Guidelines",id:"solution-guidelines",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,t.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"module-3-exercises-nvidia-isaac---perception--navigation",children:"Module 3 Exercises: NVIDIA Isaac - Perception + Navigation"})}),"\n",(0,a.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,a.jsx)(n.p,{children:"This exercise set focuses on implementing perception and navigation systems using NVIDIA Isaac. You'll work with Isaac's hardware-accelerated perception, SLAM, and navigation capabilities to build sophisticated perception and navigation systems for humanoid robots. These exercises build upon the concepts covered in the module chapters, providing hands-on experience with Isaac's tools and frameworks."}),"\n",(0,a.jsx)(n.h2,{id:"exercise-1-isaac-perception-pipeline-implementation",children:"Exercise 1: Isaac Perception Pipeline Implementation"}),"\n",(0,a.jsx)(n.h3,{id:"objective",children:"Objective"}),"\n",(0,a.jsx)(n.p,{children:"Implement a complete Isaac perception pipeline that processes RGB-D data and detects objects in the environment."}),"\n",(0,a.jsx)(n.h3,{id:"tasks",children:"Tasks"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Create an Isaac perception node that subscribes to RGB and depth camera topics"}),"\n",(0,a.jsx)(n.li,{children:"Implement object detection using Isaac ROS DNN packages"}),"\n",(0,a.jsx)(n.li,{children:"Integrate feature tracking using Isaac's optimized algorithms"}),"\n",(0,a.jsx)(n.li,{children:"Publish detection results as visualization markers"}),"\n",(0,a.jsx)(n.li,{children:"Implement performance monitoring for the perception pipeline"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"requirements",children:"Requirements"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Use Isaac ROS DNN for object detection"}),"\n",(0,a.jsx)(n.li,{children:"Implement sensor fusion between RGB and depth data"}),"\n",(0,a.jsx)(n.li,{children:"Visualize detections in RViz"}),"\n",(0,a.jsx)(n.li,{children:"Monitor processing frame rate and memory usage"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"code-template",children:"Code Template"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, CameraInfo\nfrom geometry_msgs.msg import PointStamped\nfrom visualization_msgs.msg import MarkerArray\nfrom cv_bridge import CvBridge\nimport cv2\nimport numpy as np\n\nclass IsaacPerceptionExercise(Node):\n    def __init__(self):\n        super().__init__('isaac_perception_exercise')\n\n        # Initialize components\n        self.bridge = CvBridge()\n\n        # Create subscribers for RGB and depth images\n        self.rgb_sub = self.create_subscription(\n            Image, '/camera/rgb/image_raw', self.rgb_callback, 10\n        )\n        self.depth_sub = self.create_subscription(\n            Image, '/camera/depth/image_raw', self.depth_callback, 10\n        )\n\n        # Create publisher for detections\n        self.detection_pub = self.create_publisher(MarkerArray, '/perception/detections', 10)\n\n        # Initialize Isaac perception components\n        # TODO: Initialize Isaac ROS DNN components\n\n    def rgb_callback(self, msg):\n        # TODO: Process RGB image and perform object detection\n        pass\n\n    def depth_callback(self, msg):\n        # TODO: Process depth image and fuse with RGB data\n        pass\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = IsaacPerceptionExercise()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h3,{id:"evaluation-criteria",children:"Evaluation Criteria"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Object detection accuracy above 70%"}),"\n",(0,a.jsx)(n.li,{children:"Real-time processing (10+ FPS)"}),"\n",(0,a.jsx)(n.li,{children:"Proper visualization of detections"}),"\n",(0,a.jsx)(n.li,{children:"Efficient memory usage"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"exercise-2-isaac-slam-system-integration",children:"Exercise 2: Isaac SLAM System Integration"}),"\n",(0,a.jsx)(n.h3,{id:"objective-1",children:"Objective"}),"\n",(0,a.jsx)(n.p,{children:"Implement a complete Isaac SLAM system that builds maps and localizes the robot simultaneously."}),"\n",(0,a.jsx)(n.h3,{id:"tasks-1",children:"Tasks"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Integrate Isaac Visual SLAM with your robot platform"}),"\n",(0,a.jsx)(n.li,{children:"Implement map building and localization"}),"\n",(0,a.jsx)(n.li,{children:"Add loop closure detection"}),"\n",(0,a.jsx)(n.li,{children:"Integrate IMU data for improved accuracy"}),"\n",(0,a.jsx)(n.li,{children:"Implement relocalization capabilities"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"requirements-1",children:"Requirements"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Use Isaac ROS Visual SLAM or Visual-Inertial SLAM"}),"\n",(0,a.jsx)(n.li,{children:"Build consistent maps of the environment"}),"\n",(0,a.jsx)(n.li,{children:"Maintain accurate robot localization"}),"\n",(0,a.jsx)(n.li,{children:"Handle dynamic environments"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"code-template-1",children:"Code Template"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, Imu\nfrom nav_msgs.msg import Odometry, OccupancyGrid\nfrom geometry_msgs.msg import PoseStamped\nimport tf2_ros\n\nclass IsaacSLAMExercise(Node):\n    def __init__(self):\n        super().__init__('isaac_slam_exercise')\n\n        # Create subscribers for camera and IMU data\n        self.image_sub = self.create_subscription(\n            Image, '/camera/rgb/image_raw', self.image_callback, 10\n        )\n        self.imu_sub = self.create_subscription(\n            Imu, '/imu/data', self.imu_callback, 10\n        )\n\n        # Create publishers for odometry and map\n        self.odom_pub = self.create_publisher(Odometry, '/slam/odometry', 10)\n        self.map_pub = self.create_publisher(OccupancyGrid, '/slam/map', 10)\n\n        # Initialize Isaac SLAM components\n        # TODO: Initialize Isaac SLAM components\n\n    def image_callback(self, msg):\n        # TODO: Process image for SLAM\n        pass\n\n    def imu_callback(self, msg):\n        # TODO: Integrate IMU data for improved SLAM\n        pass\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = IsaacSLAMExercise()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h3,{id:"evaluation-criteria-1",children:"Evaluation Criteria"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Map consistency and accuracy"}),"\n",(0,a.jsx)(n.li,{children:"Localization precision (within 10cm)"}),"\n",(0,a.jsx)(n.li,{children:"Loop closure detection"}),"\n",(0,a.jsx)(n.li,{children:"Computational efficiency"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"exercise-3-isaac-navigation-implementation",children:"Exercise 3: Isaac Navigation Implementation"}),"\n",(0,a.jsx)(n.h3,{id:"objective-2",children:"Objective"}),"\n",(0,a.jsx)(n.p,{children:"Implement a complete navigation system using Isaac's navigation stack that can navigate to goals while avoiding obstacles."}),"\n",(0,a.jsx)(n.h3,{id:"tasks-2",children:"Tasks"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Integrate Isaac navigation with your robot platform"}),"\n",(0,a.jsx)(n.li,{children:"Implement global path planning"}),"\n",(0,a.jsx)(n.li,{children:"Implement local trajectory control"}),"\n",(0,a.jsx)(n.li,{children:"Add obstacle avoidance capabilities"}),"\n",(0,a.jsx)(n.li,{children:"Implement human-aware navigation"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"requirements-2",children:"Requirements"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Use Isaac ROS navigation packages"}),"\n",(0,a.jsx)(n.li,{children:"Plan collision-free paths"}),"\n",(0,a.jsx)(n.li,{children:"Execute trajectories smoothly"}),"\n",(0,a.jsx)(n.li,{children:"Handle dynamic obstacles"}),"\n",(0,a.jsx)(n.li,{children:"Consider human safety in navigation"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"code-template-2",children:"Code Template"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan\nfrom geometry_msgs.msg import Twist, PoseStamped\nfrom nav_msgs.msg import Path, OccupancyGrid\nfrom std_msgs.msg import String\n\nclass IsaacNavigationExercise(Node):\n    def __init__(self):\n        super().__init__('isaac_navigation_exercise')\n\n        # Create subscribers for sensor data\n        self.scan_sub = self.create_subscription(\n            LaserScan, '/scan', self.scan_callback, 10\n        )\n\n        # Create publishers for velocity commands\n        self.cmd_vel_pub = self.create_publisher(Twist, '/cmd_vel', 10)\n\n        # Create subscriber for navigation goals\n        self.goal_sub = self.create_subscription(\n            PoseStamped, '/move_base_simple/goal', self.goal_callback, 10\n        )\n\n        # Initialize Isaac navigation components\n        # TODO: Initialize Isaac navigation components\n\n    def scan_callback(self, msg):\n        # TODO: Process laser scan for obstacle detection\n        pass\n\n    def goal_callback(self, msg):\n        # TODO: Process navigation goal and plan path\n        pass\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = IsaacNavigationExercise()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h3,{id:"evaluation-criteria-2",children:"Evaluation Criteria"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Successful navigation to goals"}),"\n",(0,a.jsx)(n.li,{children:"Obstacle avoidance"}),"\n",(0,a.jsx)(n.li,{children:"Smooth trajectory execution"}),"\n",(0,a.jsx)(n.li,{children:"Safety considerations"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"exercise-4-advanced-ai-control-for-bipedal-locomotion",children:"Exercise 4: Advanced AI Control for Bipedal Locomotion"}),"\n",(0,a.jsx)(n.h3,{id:"objective-3",children:"Objective"}),"\n",(0,a.jsx)(n.p,{children:"Implement advanced AI control algorithms for bipedal locomotion using Isaac's control frameworks."}),"\n",(0,a.jsx)(n.h3,{id:"tasks-3",children:"Tasks"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Implement balance control for bipedal robots"}),"\n",(0,a.jsx)(n.li,{children:"Create gait generation algorithms"}),"\n",(0,a.jsx)(n.li,{children:"Implement footstep planning"}),"\n",(0,a.jsx)(n.li,{children:"Add learning-based adaptation"}),"\n",(0,a.jsx)(n.li,{children:"Implement safety recovery behaviors"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"requirements-3",children:"Requirements"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Maintain robot balance during locomotion"}),"\n",(0,a.jsx)(n.li,{children:"Generate stable walking gaits"}),"\n",(0,a.jsx)(n.li,{children:"Plan appropriate footstep locations"}),"\n",(0,a.jsx)(n.li,{children:"Adapt to terrain changes"}),"\n",(0,a.jsx)(n.li,{children:"Include safety recovery behaviors"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"code-template-3",children:"Code Template"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import JointState, Imu\nfrom geometry_msgs.msg import Twist\nfrom std_msgs.msg import Float32\nimport numpy as np\n\nclass IsaacBipedalControlExercise(Node):\n    def __init__(self):\n        super().__init__('isaac_bipedal_control_exercise')\n\n        # Create subscribers for sensor data\n        self.joint_state_sub = self.create_subscription(\n            JointState, '/joint_states', self.joint_state_callback, 10\n        )\n        self.imu_sub = self.create_subscription(\n            Imu, '/imu/data', self.imu_callback, 10\n        )\n\n        # Create publishers for joint commands\n        self.joint_cmd_pub = self.create_publisher(JointState, '/joint_commands', 10)\n\n        # Initialize Isaac control components\n        # TODO: Initialize Isaac control components\n\n    def joint_state_callback(self, msg):\n        # TODO: Process joint states for control\n        pass\n\n    def imu_callback(self, msg):\n        # TODO: Process IMU data for balance control\n        pass\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = IsaacBipedalControlExercise()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h3,{id:"evaluation-criteria-3",children:"Evaluation Criteria"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Stable bipedal locomotion"}),"\n",(0,a.jsx)(n.li,{children:"Balance maintenance"}),"\n",(0,a.jsx)(n.li,{children:"Smooth gait generation"}),"\n",(0,a.jsx)(n.li,{children:"Adaptation to disturbances"}),"\n",(0,a.jsx)(n.li,{children:"Safety behavior implementation"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"exercise-5-isaac-perception-navigation-integration",children:"Exercise 5: Isaac Perception-Navigation Integration"}),"\n",(0,a.jsx)(n.h3,{id:"objective-4",children:"Objective"}),"\n",(0,a.jsx)(n.p,{children:"Create a complete system that integrates perception, SLAM, navigation, and control for autonomous humanoid operation."}),"\n",(0,a.jsx)(n.h3,{id:"tasks-4",children:"Tasks"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Integrate perception and navigation systems"}),"\n",(0,a.jsx)(n.li,{children:"Implement semantic navigation using perception data"}),"\n",(0,a.jsx)(n.li,{children:"Add human-aware navigation behaviors"}),"\n",(0,a.jsx)(n.li,{children:"Implement multi-sensor fusion"}),"\n",(0,a.jsx)(n.li,{children:"Create a complete autonomous behavior"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"requirements-4",children:"Requirements"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"End-to-end autonomous operation"}),"\n",(0,a.jsx)(n.li,{children:"Perception-guided navigation"}),"\n",(0,a.jsx)(n.li,{children:"Human-aware behaviors"}),"\n",(0,a.jsx)(n.li,{children:"Robust multi-sensor integration"}),"\n",(0,a.jsx)(n.li,{children:"Safe operation in dynamic environments"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"evaluation-criteria-4",children:"Evaluation Criteria"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Complete autonomous task execution"}),"\n",(0,a.jsx)(n.li,{children:"Integration quality between components"}),"\n",(0,a.jsx)(n.li,{children:"Performance in dynamic environments"}),"\n",(0,a.jsx)(n.li,{children:"Safety and reliability"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"self-assessment-questions",children:"Self-Assessment Questions"}),"\n",(0,a.jsx)(n.p,{children:"After completing these exercises, answer the following questions to assess your understanding:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"How does Isaac's hardware acceleration improve perception and navigation performance compared to CPU-only implementations?"}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"What are the key differences between Visual SLAM and Visual-Inertial SLAM, and when should each be used?"}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"How do you handle the computational requirements of real-time SLAM on resource-constrained platforms?"}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"What are the main challenges in bipedal locomotion control, and how does Isaac address them?"}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"How do you ensure safety in autonomous navigation systems using Isaac?"}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"project-extension",children:"Project Extension"}),"\n",(0,a.jsx)(n.p,{children:"For additional challenge, implement a complete humanoid robot that can:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Navigate to specified locations in an unknown environment"}),"\n",(0,a.jsx)(n.li,{children:"Detect and identify objects of interest"}),"\n",(0,a.jsx)(n.li,{children:"Interact with objects using manipulation capabilities"}),"\n",(0,a.jsx)(n.li,{children:"Respond appropriately to human presence and commands"}),"\n",(0,a.jsx)(n.li,{children:"Adapt its behavior based on environmental conditions"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"resources-and-references",children:"Resources and References"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://docs.nvidia.com/isaac/isaac_ros/",children:"NVIDIA Isaac ROS Documentation"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://docs.omniverse.nvidia.com/isaacsim/latest/",children:"Isaac Sim User Guide"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://navigation.ros.org/",children:"ROS 2 Navigation Documentation"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://docs.opencv.org/",children:"Computer Vision and Deep Learning Resources"})}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"solution-guidelines",children:"Solution Guidelines"}),"\n",(0,a.jsx)(n.p,{children:"Solutions to these exercises should demonstrate:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Proper integration with Isaac's hardware-accelerated components"}),"\n",(0,a.jsx)(n.li,{children:"Efficient use of GPU resources"}),"\n",(0,a.jsx)(n.li,{children:"Robust performance in real-world scenarios"}),"\n",(0,a.jsx)(n.li,{children:"Proper error handling and safety considerations"}),"\n",(0,a.jsx)(n.li,{children:"Clean, well-documented code following ROS 2 best practices"}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>o});var s=i(6540);const a={},t=s.createContext(a);function r(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);